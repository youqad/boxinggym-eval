# GLM-4.7 (upgraded from 4.6)
# 200K context window
# Requires ZHIPUAI_API_KEY
# Anthropic and OpenAI-compatible API endpoint

model_name: "anthropic/glm-4.7"
temperature: 0.0
max_tokens: 32768  # Reduced from 131072 to avoid API timeouts

# API Configuration (Z.AI endpoint - uses Anthropic-compatible API)
# As per LiteLLM docs: https://github.com/BerriAI/litellm/issues/13059
# Model format: anthropic/glm-4.7 for Anthropic-compatible endpoint
api_base: "https://api.z.ai/api/anthropic"
api_key: ${oc.env:ZHIPUAI_API_KEY,null}

# Required for custom endpoints
custom_llm_provider: "anthropic"

supports_system_message: true
supports_thinking: true
supports_streaming: true
supports_vision: false

context_window: 200000
reasoning_capable: true
