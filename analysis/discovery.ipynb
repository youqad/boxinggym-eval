{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'boxing_gym'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mlogging\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mboxing_gym\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01menvs\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlocation_finding\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mboxing_gym\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01menvs\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mhyperbolic_temporal_discount\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mboxing_gym\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01menvs\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdeath_process\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'boxing_gym'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\".\"))\n",
    "import os\n",
    "import tqdm\n",
    "import json\n",
    "import logging\n",
    "import numpy as np\n",
    "import boxing_gym.envs.location_finding\n",
    "import boxing_gym.envs.hyperbolic_temporal_discount\n",
    "import boxing_gym.envs.death_process\n",
    "import boxing_gym.envs.irt\n",
    "import boxing_gym.envs.survival_analysis\n",
    "import boxing_gym.envs.peregrines\n",
    "import boxing_gym.envs.dugongs\n",
    "import boxing_gym.envs.lotka_volterra\n",
    "import boxing_gym.envs.moral_machines\n",
    "import boxing_gym.envs.emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tqdm\n",
    "import json\n",
    "import logging\n",
    "import random\n",
    "import numpy as np\n",
    "from boxing_gym.envs import location_finding\n",
    "from boxing_gym.envs import hyperbolic_temporal_discount\n",
    "from boxing_gym.envs import death_process\n",
    "from boxing_gym.envs import irt\n",
    "from boxing_gym.envs import survival_analysis\n",
    "from boxing_gym.envs import peregrines\n",
    "from boxing_gym.envs import dugongs\n",
    "from boxing_gym.envs import lotka_volterra\n",
    "from boxing_gym.envs import moral_machines\n",
    "from boxing_gym.envs import emotion\n",
    "# from boxing_gym.envs import rat_tumor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = \"/sailhome/agam/boxing-gym/results/\"\n",
    "exp = \"discovery\"\n",
    "# env = \"hyperbolic_temporal_discount\"\n",
    "env = \"location_finding\"\n",
    "# env = \"death_process\"\n",
    "# env = \"irt\"\n",
    "# env = \"dugongs\"\n",
    "# env = \"survival\"\n",
    "# env = \"peregrines\"\n",
    "# env = \"morals\"\n",
    "# env = \"emotion\"\n",
    "# env = \"lotka_volterra\"\n",
    "goal = \"direct_discovery\"\n",
    "model = 'qwen2.5-7b-instruct'#\"gpt-4o\"\n",
    "seeds = [1,2,3,4,5] \n",
    "box = False \n",
    "if box:\n",
    "    model += \"-boxloop\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nametoenv = {    \n",
    "    \"location_finding\": boxing_gym.envs.location_finding.Signal,\n",
    "    \"hyperbolic_temporal_discount\": boxing_gym.envs.hyperbolic_temporal_discount.TemporalDiscount,\n",
    "    \"death_process\": boxing_gym.envs.death_process.DeathProcess,\n",
    "    \"irt\": boxing_gym.envs.irt.IRT,\n",
    "    \"survival\": boxing_gym.envs.survival_analysis.SurvivalAnalysis,\n",
    "    \"dugongs\": boxing_gym.envs.dugongs.Dugongs,\n",
    "    \"peregrines\": boxing_gym.envs.peregrines.Peregrines,\n",
    "    \"morals\": boxing_gym.envs.moral_machines.MoralMachine,\n",
    "    \"emotion\": boxing_gym.envs.emotion.EmotionFromOutcome,\n",
    "    \"lotka_volterra\": boxing_gym.envs.lotka_volterra.LotkaVolterra,\n",
    "    #\"rat_tumor\": boxing_gym.envs.rat_tumor.RatTumorModel\n",
    "}\n",
    "nameenvtogoal = {\n",
    "    (\"hyperbolic_temporal_discount\", \"direct\"): boxing_gym.envs.hyperbolic_temporal_discount.DirectGoal,\n",
    "    (\"hyperbolic_temporal_discount\", \"discount\"): boxing_gym.envs.hyperbolic_temporal_discount.DiscountGoal,\n",
    "    (\"hyperbolic_temporal_discount\", \"direct_discovery\"): boxing_gym.envs.hyperbolic_temporal_discount.DirectGoalNaive,\n",
    "    (\"location_finding\", \"direct\"): boxing_gym.envs.location_finding.DirectGoal,\n",
    "    (\"location_finding\", \"source\"): boxing_gym.envs.location_finding.SourceGoal,\n",
    "    (\"location_finding\", \"direct_discovery\"): boxing_gym.envs.location_finding.DirectGoalNaive,\n",
    "    (\"death_process\", \"direct\"): boxing_gym.envs.death_process.DirectDeath,\n",
    "    (\"death_process\", \"direct_discovery\"): boxing_gym.envs.death_process.DirectDeathNaive,\n",
    "    (\"death_process\", \"infection\"): boxing_gym.envs.death_process.InfectionRate,\n",
    "    (\"irt\", \"direct\"): boxing_gym.envs.irt.DirectCorrectness,\n",
    "    (\"irt\", \"direct_discovery\"): boxing_gym.envs.irt.DirectCorrectnessNaive,\n",
    "    (\"irt\", \"best_student\"): boxing_gym.envs.irt.BestStudent,\n",
    "    (\"irt\", \"difficult_question\"): boxing_gym.envs.irt.DifficultQuestion,\n",
    "    (\"irt\", \"discriminate_question\"): boxing_gym.envs.irt.DiscriminatingQuestion,\n",
    "    (\"survival\", \"direct\"): boxing_gym.envs.survival_analysis.DirectGoal,\n",
    "    (\"survival\", \"direct_discovery\"): boxing_gym.envs.survival_analysis.DirectGoalNaive,\n",
    "    (\"dugongs\", \"direct\"): boxing_gym.envs.dugongs.DirectGoal,\n",
    "    (\"dugongs\", \"direct_discovery\"): boxing_gym.envs.dugongs.DirectGoalNaive,\n",
    "    (\"peregrines\", \"direct\"): boxing_gym.envs.peregrines.DirectGoal,\n",
    "    (\"peregrines\", \"direct_discovery\"): boxing_gym.envs.peregrines.DirectGoalNaive,\n",
    "    (\"emotion\", \"direct\"): boxing_gym.envs.emotion.DirectEmotionPrediction,\n",
    "    (\"emotion\", \"direct_discovery\"): boxing_gym.envs.emotion.DirectEmotionNaive,\n",
    "    (\"morals\", \"direct\"): boxing_gym.envs.moral_machines.DirectPrediction,\n",
    "    (\"morals\", \"direct_discovery\"): boxing_gym.envs.moral_machines.DirectPredictionNaive,\n",
    "    (\"lotka_volterra\", \"direct\"): boxing_gym.envs.lotka_volterra.DirectGoal,\n",
    "    (\"lotka_volterra\", \"direct_discovery\"): boxing_gym.envs.lotka_volterra.DirectGoalNaive,\n",
    "    # (\"rat_tumor\", \"direct\"): boxing_gym.envs.rat_tumor.DirectGoal,\n",
    "    # (\"rat_tumor\", \"direct_discovery\"): boxing_gym.envs.rat_tumor.DirectGoalNaive\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<boxing_gym.envs.lotka_volterra.LotkaVolterra object at 0x7f283ede7350>\n"
     ]
    }
   ],
   "source": [
    "environ = nametoenv[env]()\n",
    "print(environ)\n",
    "goaln = nameenvtogoal[env, goal](environ)\n",
    "norm_mu = goaln.norm_mu\n",
    "norm_sigma = goaln.norm_sigma\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [os.path.join(results_dir, env, f\"{goal}_{model}_{exp}_True_{seed}.json\") for seed in seeds]\n",
    "files_no_prior = [os.path.join(results_dir, env, f\"{goal}_{model}_{exp}_False_{seed}.json\") for seed in seeds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/sailhome/agam/boxing-gym/results/lotka_volterra/direct_discovery_qwen2.5-7b-instruct_discovery_True_1.json\n",
      "/sailhome/agam/boxing-gym/results/lotka_volterra/direct_discovery_qwen2.5-7b-instruct_discovery_True_2.json\n",
      "/sailhome/agam/boxing-gym/results/lotka_volterra/direct_discovery_qwen2.5-7b-instruct_discovery_True_3.json\n",
      "/sailhome/agam/boxing-gym/results/lotka_volterra/direct_discovery_qwen2.5-7b-instruct_discovery_True_4.json\n",
      "/sailhome/agam/boxing-gym/results/lotka_volterra/direct_discovery_qwen2.5-7b-instruct_discovery_True_5.json\n",
      "/sailhome/agam/boxing-gym/results/lotka_volterra/direct_discovery_qwen2.5-7b-instruct_discovery_False_1.json\n",
      "/sailhome/agam/boxing-gym/results/lotka_volterra/direct_discovery_qwen2.5-7b-instruct_discovery_False_2.json\n",
      "/sailhome/agam/boxing-gym/results/lotka_volterra/direct_discovery_qwen2.5-7b-instruct_discovery_False_3.json\n",
      "/sailhome/agam/boxing-gym/results/lotka_volterra/direct_discovery_qwen2.5-7b-instruct_discovery_False_4.json\n",
      "/sailhome/agam/boxing-gym/results/lotka_volterra/direct_discovery_qwen2.5-7b-instruct_discovery_False_5.json\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for file in files:\n",
    "    print(file)\n",
    "    with open(file, \"r\") as f:\n",
    "        data.append(json.load(f))\n",
    "data_no_prior = []\n",
    "for file in files_no_prior:\n",
    "    print(file)\n",
    "    with open(file, \"r\") as f:\n",
    "        data_no_prior.append(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(data[0]['data']['queries']))\n",
    "# (mean, std), questions, gts, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm_mu: 8.327445247142364, norm_sigma: 17.548285564117467\n"
     ]
    }
   ],
   "source": [
    "environ = nametoenv[env]()\n",
    "goaln = nameenvtogoal[env, goal](environ)\n",
    "try:\n",
    "    norm_mu = goaln.norm_mu\n",
    "    norm_sigma = goaln.norm_sigma\n",
    "except:\n",
    "    norm_mu = 0\n",
    "    norm_sigma = 1\n",
    "    \n",
    "print(f\"norm_mu: {norm_mu}, norm_sigma: {norm_sigma}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "errs, stds = [], []\n",
    "for d in data:\n",
    "    errs.append([])\n",
    "    stds.append([])\n",
    "    for r in d['data']['results']: \n",
    "        errs[-1].append(r[0][0])\n",
    "        stds[-1].append(r[0][1])\n",
    "errs_no_prior, stds_no_prior = [], []\n",
    "for d in data_no_prior:\n",
    "    errs_no_prior.append([])\n",
    "    stds_no_prior.append([])\n",
    "    for r in d['data']['results']: \n",
    "        errs_no_prior[-1].append(r[0][0])\n",
    "        stds_no_prior[-1].append(r[0][1])\n",
    "\n",
    "errs = np.array(errs)\n",
    "stds = np.array(stds)\n",
    "errs_no_prior = np.array(errs_no_prior)\n",
    "stds_no_prior = np.array(stds_no_prior)\n",
    "\n",
    "if env == \"location_finding\" and \"direct\" in goal:\n",
    "    # clip\n",
    "    errs = np.clip(errs, 0, 500)\n",
    "    errs_no_prior = np.clip(errs_no_prior, 0, 500)\n",
    "\n",
    "\n",
    "# normalize\n",
    "errs = (errs - norm_mu) / norm_sigma\n",
    "errs_no_prior = (errs_no_prior - norm_mu) / norm_sigma\n",
    "\n",
    "if env == \"hyperbolic_temporal_discount\" and \"direct\" in goal:\n",
    "    errs = 1 - errs\n",
    "    errs_no_prior = 1 - errs_no_prior\n",
    "# elif env == \"peregrines\":\n",
    "#     errs = errs ** 0.5\n",
    "#     errs_no_prior = errs_no_prior ** 0.5\n",
    "elif env == \"survival\":\n",
    "    errs = 1 - errs\n",
    "    errs_no_prior = 1 - errs_no_prior\n",
    "if env == \"morals\":\n",
    "    print(\"removing\")\n",
    "    errs = 1 - errs\n",
    "\n",
    "mean_score = np.mean(errs, axis=0)\n",
    "ci_95 = 1.96 * np.std(errs, axis=0) / np.sqrt(len(errs))\n",
    "mean_score_no_prior = np.mean(errs_no_prior, axis=0)\n",
    "ci_95_no_prior = 1.96 * np.std(errs_no_prior, axis=0) / np.sqrt(len(errs_no_prior))\n",
    "\n",
    "\n",
    "\n",
    "print(mean_score.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06339963] [0.2217267] [-0.02492809] [0.12396685]\n"
     ]
    }
   ],
   "source": [
    "print(mean_score, ci_95, mean_score_no_prior, ci_95_no_prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing environment: hyperbolic_temporal_discount\n",
      "Processing environment: location_finding\n",
      "Processing environment: death_process\n",
      "Processing environment: irt\n",
      "Processing environment: dugongs\n",
      "Processing environment: survival\n",
      "Processing environment: peregrines\n",
      "Processing environment: morals\n",
      "File not found: /sailhome/agam/boxing-gym/results/morals/direct_discovery_OpenThinker-7B_discovery_False_1.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/morals/direct_discovery_OpenThinker-7B_discovery_False_2.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/morals/direct_discovery_OpenThinker-7B_discovery_False_3.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/morals/direct_discovery_OpenThinker-7B_discovery_False_4.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/morals/direct_discovery_OpenThinker-7B_discovery_False_5.json\n",
      "Processing environment: emotion\n",
      "File not found: /sailhome/agam/boxing-gym/results/emotion/direct_discovery_OpenThinker-7B_discovery_False_1.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/emotion/direct_discovery_OpenThinker-7B_discovery_False_2.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/emotion/direct_discovery_OpenThinker-7B_discovery_False_3.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/emotion/direct_discovery_OpenThinker-7B_discovery_False_4.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/emotion/direct_discovery_OpenThinker-7B_discovery_False_5.json\n",
      "Processing environment: lotka_volterra\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[32m/tmp/user/23893/ipykernel_2226432/1469595641.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    196\u001b[39m     \u001b[33m'No Prior (95% CI)'\u001b[39m\n\u001b[32m    197\u001b[39m ])\n\u001b[32m    198\u001b[39m \n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m env, values \u001b[38;5;28;01min\u001b[39;00m results.items():\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m     df = df.append({\n\u001b[32m    201\u001b[39m         \u001b[33m'Environment'\u001b[39m: env,\n\u001b[32m    202\u001b[39m         \u001b[33m'With Prior (Mean)'\u001b[39m: \u001b[33mf\"{values['with_prior_mean']:.4f}\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isinstance(values[\u001b[33m'with_prior_mean'\u001b[39m], (int, float)) \u001b[38;5;28;01melse\u001b[39;00m values[\u001b[33m'with_prior_mean'\u001b[39m],\n\u001b[32m    203\u001b[39m         \u001b[33m'With Prior (95% CI)'\u001b[39m: \u001b[33mf\"±{values['with_prior_ci']:.4f}\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isinstance(values[\u001b[33m'with_prior_ci'\u001b[39m], (int, float)) \u001b[38;5;28;01melse\u001b[39;00m values[\u001b[33m'with_prior_ci'\u001b[39m],\n",
      "\u001b[32m/scr/agam/miniconda3/envs/boxing-gym-env/lib/python3.11/site-packages/pandas/core/generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   6295\u001b[39m             \u001b[38;5;28;01mand\u001b[39;00m name \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01min\u001b[39;00m self._accessors\n\u001b[32m   6296\u001b[39m             \u001b[38;5;28;01mand\u001b[39;00m self._info_axis._can_hold_identifiers_and_holds_name(name)\n\u001b[32m   6297\u001b[39m         ):\n\u001b[32m   6298\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self[name]\n\u001b[32m-> \u001b[39m\u001b[32m6299\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m object.__getattribute__(self, name)\n",
      "\u001b[31mAttributeError\u001b[39m: 'DataFrame' object has no attribute 'append'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: [alpha, beta, gamma, responses]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing environment: hyperbolic_temporal_discount\n",
      "hyperbolic_temporal_discount normalization: mu=0.5, sigma=0.4692829610160591\n",
      "File not found: /sailhome/agam/boxing-gym/results/hyperbolic_temporal_discount/direct_discovery_OpenThinker-7b_discovery_True_1.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/hyperbolic_temporal_discount/direct_discovery_OpenThinker-7b_discovery_True_2.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/hyperbolic_temporal_discount/direct_discovery_OpenThinker-7b_discovery_True_3.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/hyperbolic_temporal_discount/direct_discovery_OpenThinker-7b_discovery_True_4.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/hyperbolic_temporal_discount/direct_discovery_OpenThinker-7b_discovery_True_5.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/hyperbolic_temporal_discount/direct_discovery_OpenThinker-7b_discovery_False_1.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/hyperbolic_temporal_discount/direct_discovery_OpenThinker-7b_discovery_False_2.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/hyperbolic_temporal_discount/direct_discovery_OpenThinker-7b_discovery_False_3.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/hyperbolic_temporal_discount/direct_discovery_OpenThinker-7b_discovery_False_4.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/hyperbolic_temporal_discount/direct_discovery_OpenThinker-7b_discovery_False_5.json\n",
      "Processing environment: location_finding\n",
      "location_finding normalization: mu=12.59, sigma=38.03\n",
      "File not found: /sailhome/agam/boxing-gym/results/location_finding/direct_discovery_OpenThinker-7b_discovery_True_1.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/location_finding/direct_discovery_OpenThinker-7b_discovery_True_2.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/location_finding/direct_discovery_OpenThinker-7b_discovery_True_3.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/location_finding/direct_discovery_OpenThinker-7b_discovery_True_4.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/location_finding/direct_discovery_OpenThinker-7b_discovery_True_5.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/location_finding/direct_discovery_OpenThinker-7b_discovery_False_1.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/location_finding/direct_discovery_OpenThinker-7b_discovery_False_2.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/location_finding/direct_discovery_OpenThinker-7b_discovery_False_3.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/location_finding/direct_discovery_OpenThinker-7b_discovery_False_4.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/location_finding/direct_discovery_OpenThinker-7b_discovery_False_5.json\n",
      "Processing environment: death_process\n",
      "death_process normalization: mu=222.2998, sigma=189.76853880440774\n",
      "File not found: /sailhome/agam/boxing-gym/results/death_process/direct_discovery_OpenThinker-7b_discovery_True_1.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/death_process/direct_discovery_OpenThinker-7b_discovery_True_2.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/death_process/direct_discovery_OpenThinker-7b_discovery_True_3.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/death_process/direct_discovery_OpenThinker-7b_discovery_True_4.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/death_process/direct_discovery_OpenThinker-7b_discovery_True_5.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/death_process/direct_discovery_OpenThinker-7b_discovery_False_1.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/death_process/direct_discovery_OpenThinker-7b_discovery_False_2.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/death_process/direct_discovery_OpenThinker-7b_discovery_False_3.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/death_process/direct_discovery_OpenThinker-7b_discovery_False_4.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/death_process/direct_discovery_OpenThinker-7b_discovery_False_5.json\n",
      "Processing environment: irt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: [alpha, beta, gamma, responses]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "irt normalization: mu=0.5, sigma=0.5\n",
      "File not found: /sailhome/agam/boxing-gym/results/irt/direct_discovery_OpenThinker-7b_discovery_True_1.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/irt/direct_discovery_OpenThinker-7b_discovery_True_2.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/irt/direct_discovery_OpenThinker-7b_discovery_True_3.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/irt/direct_discovery_OpenThinker-7b_discovery_True_4.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/irt/direct_discovery_OpenThinker-7b_discovery_True_5.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/irt/direct_discovery_OpenThinker-7b_discovery_False_1.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/irt/direct_discovery_OpenThinker-7b_discovery_False_2.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/irt/direct_discovery_OpenThinker-7b_discovery_False_3.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/irt/direct_discovery_OpenThinker-7b_discovery_False_4.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/irt/direct_discovery_OpenThinker-7b_discovery_False_5.json\n",
      "Processing environment: dugongs\n",
      "dugongs normalization: mu=0.9058681693402041, sigma=9.23419251690869\n",
      "File not found: /sailhome/agam/boxing-gym/results/dugongs/direct_discovery_OpenThinker-7b_discovery_True_1.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/dugongs/direct_discovery_OpenThinker-7b_discovery_True_2.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/dugongs/direct_discovery_OpenThinker-7b_discovery_True_3.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/dugongs/direct_discovery_OpenThinker-7b_discovery_True_4.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/dugongs/direct_discovery_OpenThinker-7b_discovery_True_5.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/dugongs/direct_discovery_OpenThinker-7b_discovery_False_1.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/dugongs/direct_discovery_OpenThinker-7b_discovery_False_2.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/dugongs/direct_discovery_OpenThinker-7b_discovery_False_3.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/dugongs/direct_discovery_OpenThinker-7b_discovery_False_4.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/dugongs/direct_discovery_OpenThinker-7b_discovery_False_5.json\n",
      "Processing environment: survival\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survival normalization: mu=0.2604, sigma=0.43885286828275377\n",
      "File not found: /sailhome/agam/boxing-gym/results/survival/direct_discovery_OpenThinker-7b_discovery_True_1.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/survival/direct_discovery_OpenThinker-7b_discovery_True_2.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/survival/direct_discovery_OpenThinker-7b_discovery_True_3.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/survival/direct_discovery_OpenThinker-7b_discovery_True_4.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/survival/direct_discovery_OpenThinker-7b_discovery_True_5.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/survival/direct_discovery_OpenThinker-7b_discovery_False_1.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/survival/direct_discovery_OpenThinker-7b_discovery_False_2.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/survival/direct_discovery_OpenThinker-7b_discovery_False_3.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/survival/direct_discovery_OpenThinker-7b_discovery_False_4.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/survival/direct_discovery_OpenThinker-7b_discovery_False_5.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n",
      "Sampling: [death_outcome]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing environment: peregrines\n",
      "peregrines normalization: mu=10991.5464, sigma=15725.115658658306\n",
      "File not found: /sailhome/agam/boxing-gym/results/peregrines/direct_discovery_OpenThinker-7b_discovery_True_1.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/peregrines/direct_discovery_OpenThinker-7b_discovery_True_2.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/peregrines/direct_discovery_OpenThinker-7b_discovery_True_3.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/peregrines/direct_discovery_OpenThinker-7b_discovery_True_4.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/peregrines/direct_discovery_OpenThinker-7b_discovery_True_5.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/peregrines/direct_discovery_OpenThinker-7b_discovery_False_1.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/peregrines/direct_discovery_OpenThinker-7b_discovery_False_2.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/peregrines/direct_discovery_OpenThinker-7b_discovery_False_3.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/peregrines/direct_discovery_OpenThinker-7b_discovery_False_4.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/peregrines/direct_discovery_OpenThinker-7b_discovery_False_5.json\n",
      "Processing environment: morals\n",
      "morals normalization: mu=0.424, sigma=0.494190246767376\n",
      "File not found: /sailhome/agam/boxing-gym/results/morals/direct_discovery_OpenThinker-7b_discovery_True_1.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/morals/direct_discovery_OpenThinker-7b_discovery_True_2.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/morals/direct_discovery_OpenThinker-7b_discovery_True_3.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/morals/direct_discovery_OpenThinker-7b_discovery_True_4.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/morals/direct_discovery_OpenThinker-7b_discovery_True_5.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/morals/direct_discovery_OpenThinker-7b_discovery_False_1.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/morals/direct_discovery_OpenThinker-7b_discovery_False_2.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/morals/direct_discovery_OpenThinker-7b_discovery_False_3.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/morals/direct_discovery_OpenThinker-7b_discovery_False_4.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/morals/direct_discovery_OpenThinker-7b_discovery_False_5.json\n",
      "Processing environment: emotion\n",
      "gpt-4o\n",
      "emotion normalization: mu=1.58508525, sigma=0.7237143937677741\n",
      "File not found: /sailhome/agam/boxing-gym/results/emotion/direct_discovery_OpenThinker-7b_discovery_True_1.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/emotion/direct_discovery_OpenThinker-7b_discovery_True_2.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/emotion/direct_discovery_OpenThinker-7b_discovery_True_3.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/emotion/direct_discovery_OpenThinker-7b_discovery_True_4.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/emotion/direct_discovery_OpenThinker-7b_discovery_True_5.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/emotion/direct_discovery_OpenThinker-7b_discovery_False_1.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/emotion/direct_discovery_OpenThinker-7b_discovery_False_2.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/emotion/direct_discovery_OpenThinker-7b_discovery_False_3.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/emotion/direct_discovery_OpenThinker-7b_discovery_False_4.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/emotion/direct_discovery_OpenThinker-7b_discovery_False_5.json\n",
      "gpt-4o\n",
      "Processing environment: lotka_volterra\n",
      "lotka_volterra normalization: mu=8.327445247142364, sigma=17.548285564117467\n",
      "File not found: /sailhome/agam/boxing-gym/results/lotka_volterra/direct_discovery_OpenThinker-7b_discovery_True_1.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/lotka_volterra/direct_discovery_OpenThinker-7b_discovery_True_2.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/lotka_volterra/direct_discovery_OpenThinker-7b_discovery_True_3.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/lotka_volterra/direct_discovery_OpenThinker-7b_discovery_True_4.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/lotka_volterra/direct_discovery_OpenThinker-7b_discovery_True_5.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/lotka_volterra/direct_discovery_OpenThinker-7b_discovery_False_1.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/lotka_volterra/direct_discovery_OpenThinker-7b_discovery_False_2.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/lotka_volterra/direct_discovery_OpenThinker-7b_discovery_False_3.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/lotka_volterra/direct_discovery_OpenThinker-7b_discovery_False_4.json\n",
      "File not found: /sailhome/agam/boxing-gym/results/lotka_volterra/direct_discovery_OpenThinker-7b_discovery_False_5.json\n",
      "+------------------------------+------------+------------+-------------------+---------------------+-----------------+-------------------+\n",
      "|         Environment          |   Norm μ   |   Norm σ   | With Prior (Mean) | With Prior (95% CI) | No Prior (Mean) | No Prior (95% CI) |\n",
      "+------------------------------+------------+------------+-------------------+---------------------+-----------------+-------------------+\n",
      "| hyperbolic_temporal_discount |   0.5000   |   0.4693   |        N/A        |         N/A         |       N/A       |        N/A        |\n",
      "|       location_finding       |  12.5900   |  38.0300   |        N/A        |         N/A         |       N/A       |        N/A        |\n",
      "|        death_process         |  222.2998  |  189.7685  |        N/A        |         N/A         |       N/A       |        N/A        |\n",
      "|             irt              |   0.5000   |   0.5000   |        N/A        |         N/A         |       N/A       |        N/A        |\n",
      "|           dugongs            |   0.9059   |   9.2342   |        N/A        |         N/A         |       N/A       |        N/A        |\n",
      "|           survival           |   0.2604   |   0.4389   |        N/A        |         N/A         |       N/A       |        N/A        |\n",
      "|          peregrines          | 10991.5464 | 15725.1157 |        N/A        |         N/A         |       N/A       |        N/A        |\n",
      "|            morals            |   0.4240   |   0.4942   |        N/A        |         N/A         |       N/A       |        N/A        |\n",
      "|           emotion            |   1.5851   |   0.7237   |        N/A        |         N/A         |       N/A       |        N/A        |\n",
      "|        lotka_volterra        |   8.3274   |  17.5483   |        N/A        |         N/A         |       N/A       |        N/A        |\n",
      "+------------------------------+------------+------------+-------------------+---------------------+-----------------+-------------------+\n",
      "Results saved to /sailhome/agam/boxing-gym/results/OpenThinker-7b_discovery_direct_discovery_all_environments.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import importlib\n",
    "from tabulate import tabulate  # If available, otherwise we'll use pandas formatting\n",
    "import sys\n",
    "\n",
    "# Add the boxing_gym module to system path if needed\n",
    "# Adjust this path as necessary for your environment\n",
    "# sys.path.append(\"/path/to/boxing-gym\")\n",
    "\n",
    "results_dir = \"/sailhome/agam/boxing-gym/results/\"\n",
    "exp = \"discovery\"\n",
    "goal = \"direct_discovery\"\n",
    "model = 'OpenThinker-7B'  # \"gpt-4o\"\n",
    "seeds = [1, 2, 3, 4, 5]\n",
    "box = False\n",
    "if box:\n",
    "    model += \"-boxloop\"\n",
    "\n",
    "# All environments to process\n",
    "environments = [\n",
    "    \"hyperbolic_temporal_discount\",\n",
    "    \"location_finding\",\n",
    "    \"death_process\",\n",
    "    \"irt\",\n",
    "    \"dugongs\",\n",
    "    \"survival\",\n",
    "    \"peregrines\",\n",
    "    \"morals\",\n",
    "    \"emotion\",\n",
    "    \"lotka_volterra\"\n",
    "]\n",
    "\n",
    "# Import boxing_gym\n",
    "import boxing_gym\n",
    "\n",
    "# Define the environment and goal mappings\n",
    "nametoenv = {\n",
    "    \"location_finding\": boxing_gym.envs.location_finding.Signal,\n",
    "    \"hyperbolic_temporal_discount\": boxing_gym.envs.hyperbolic_temporal_discount.TemporalDiscount,\n",
    "    \"death_process\": boxing_gym.envs.death_process.DeathProcess,\n",
    "    \"irt\": boxing_gym.envs.irt.IRT,\n",
    "    \"survival\": boxing_gym.envs.survival_analysis.SurvivalAnalysis,\n",
    "    \"dugongs\": boxing_gym.envs.dugongs.Dugongs,\n",
    "    \"peregrines\": boxing_gym.envs.peregrines.Peregrines,\n",
    "    \"morals\": boxing_gym.envs.moral_machines.MoralMachine,\n",
    "    \"emotion\": boxing_gym.envs.emotion.EmotionFromOutcome,\n",
    "    \"lotka_volterra\": boxing_gym.envs.lotka_volterra.LotkaVolterra,\n",
    "}\n",
    "\n",
    "nameenvtogoal = {\n",
    "    (\"hyperbolic_temporal_discount\", \"direct_discovery\"): boxing_gym.envs.hyperbolic_temporal_discount.DirectGoalNaive,\n",
    "    (\"location_finding\", \"direct_discovery\"): boxing_gym.envs.location_finding.DirectGoalNaive,\n",
    "    (\"death_process\", \"direct_discovery\"): boxing_gym.envs.death_process.DirectDeathNaive,\n",
    "    (\"irt\", \"direct_discovery\"): boxing_gym.envs.irt.DirectCorrectnessNaive,\n",
    "    (\"survival\", \"direct_discovery\"): boxing_gym.envs.survival_analysis.DirectGoalNaive,\n",
    "    (\"dugongs\", \"direct_discovery\"): boxing_gym.envs.dugongs.DirectGoalNaive,\n",
    "    (\"peregrines\", \"direct_discovery\"): boxing_gym.envs.peregrines.DirectGoalNaive,\n",
    "    (\"emotion\", \"direct_discovery\"): boxing_gym.envs.emotion.DirectEmotionNaive,\n",
    "    (\"morals\", \"direct_discovery\"): boxing_gym.envs.moral_machines.DirectPredictionNaive,\n",
    "    (\"lotka_volterra\", \"direct_discovery\"): boxing_gym.envs.lotka_volterra.DirectGoalNaive,\n",
    "}\n",
    "\n",
    "# Function to get normalization parameters from actual environment objects\n",
    "def get_norm_params(env, goal):\n",
    "    try:\n",
    "        environ = nametoenv[env]()\n",
    "        goaln = nameenvtogoal[(env, goal)](environ)\n",
    "        \n",
    "        try:\n",
    "            norm_mu = goaln.norm_mu\n",
    "            norm_sigma = goaln.norm_sigma\n",
    "        except AttributeError:\n",
    "            print(f\"Warning: Could not get norm_mu or norm_sigma for {env}. Using defaults.\")\n",
    "            norm_mu = 0\n",
    "            norm_sigma = 1\n",
    "        \n",
    "        return norm_mu, norm_sigma\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting normalization parameters for {env}: {e}\")\n",
    "        return 0, 1\n",
    "\n",
    "# Function to load and process data for a specific environment\n",
    "def process_environment_data(env, goal, model, exp, seeds, results_dir):\n",
    "    # Construct file paths\n",
    "    files_with_prior = [os.path.join(results_dir, env, f\"{goal}_{model}_{exp}_True_{seed}.json\") for seed in seeds]\n",
    "    files_no_prior = [os.path.join(results_dir, env, f\"{goal}_{model}_{exp}_False_{seed}.json\") for seed in seeds]\n",
    "    \n",
    "    # Load data\n",
    "    data_with_prior = []\n",
    "    for file in files_with_prior:\n",
    "        try:\n",
    "            with open(file, \"r\") as f:\n",
    "                data_with_prior.append(json.load(f))\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File not found: {file}\")\n",
    "    \n",
    "    data_no_prior = []\n",
    "    for file in files_no_prior:\n",
    "        try:\n",
    "            with open(file, \"r\") as f:\n",
    "                data_no_prior.append(json.load(f))\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File not found: {file}\")\n",
    "    \n",
    "    # Get normalization parameters\n",
    "    norm_mu, norm_sigma = get_norm_params(env, goal)\n",
    "    \n",
    "    # Extract errors and stds\n",
    "    errs, stds = [], []\n",
    "    for d in data_with_prior:\n",
    "        errs.append([])\n",
    "        stds.append([])\n",
    "        for r in d['data']['results']: \n",
    "            errs[-1].append(r[0][0])\n",
    "            stds[-1].append(r[0][1])\n",
    "    \n",
    "    errs_no_prior, stds_no_prior = [], []\n",
    "    for d in data_no_prior:\n",
    "        errs_no_prior.append([])\n",
    "        stds_no_prior.append([])\n",
    "        for r in d['data']['results']: \n",
    "            errs_no_prior[-1].append(r[0][0])\n",
    "            stds_no_prior[-1].append(r[0][1])\n",
    "    # cleanup\n",
    "    # Convert to numpy arrays\n",
    "    errs = np.array(errs)\n",
    "    stds = np.array(stds)\n",
    "    errs_no_prior = np.array(errs_no_prior)\n",
    "    stds_no_prior = np.array(stds_no_prior)\n",
    "    \n",
    "    # Special handling for specific environments\n",
    "    if env == \"location_finding\" and \"direct\" in goal:\n",
    "        # Clip values\n",
    "        errs = np.clip(errs, 0, 10000)\n",
    "        errs_no_prior = np.clip(errs_no_prior, 0, 10000)\n",
    "    \n",
    "    # Normalize\n",
    "    errs = (errs - norm_mu) / norm_sigma\n",
    "    errs_no_prior = (errs_no_prior - norm_mu) / norm_sigma\n",
    "    \n",
    "    # Special transformations for specific environments\n",
    "    if env == \"hyperbolic_temporal_discount\" and \"direct\" in goal:\n",
    "        errs = 1 - errs\n",
    "        errs_no_prior = 1 - errs_no_prior\n",
    "    elif env == \"survival\":\n",
    "        errs = 1 - errs\n",
    "        errs_no_prior = 1 - errs_no_prior\n",
    "    elif env == \"morals\":\n",
    "        errs = 1 - errs\n",
    "        errs_no_prior = 1 - errs_no_prior\n",
    "    \n",
    "    # Calculate mean scores and confidence intervals\n",
    "    if len(errs) > 0:\n",
    "        mean_score = np.mean(errs, axis=0)\n",
    "        ci_95 = 1.96 * np.std(errs, axis=0) / np.sqrt(len(errs))\n",
    "    else:\n",
    "        mean_score = np.array([np.nan])\n",
    "        ci_95 = np.array([np.nan])\n",
    "    \n",
    "    if len(errs_no_prior) > 0:\n",
    "        mean_score_no_prior = np.mean(errs_no_prior, axis=0)\n",
    "        ci_95_no_prior = 1.96 * np.std(errs_no_prior, axis=0) / np.sqrt(len(errs_no_prior))\n",
    "    else:\n",
    "        mean_score_no_prior = np.array([np.nan])\n",
    "        ci_95_no_prior = np.array([np.nan])\n",
    "    \n",
    "    return mean_score, ci_95, mean_score_no_prior, ci_95_no_prior\n",
    "\n",
    "# Process all environments and collect results\n",
    "results = {}\n",
    "norm_params = {}  # Store the norm parameters for each environment\n",
    "\n",
    "for env in environments:\n",
    "    print(f\"Processing environment: {env}\")\n",
    "    \n",
    "    # Get the normalization parameters for this environment\n",
    "    norm_mu, norm_sigma = get_norm_params(env, goal)\n",
    "    norm_params[env] = (norm_mu, norm_sigma)\n",
    "    print(f\"{env} normalization: mu={norm_mu}, sigma={norm_sigma}\")\n",
    "    \n",
    "    try:\n",
    "        mean_score, ci_95, mean_score_no_prior, ci_95_no_prior = process_environment_data(\n",
    "            env, goal, model, exp, seeds, results_dir\n",
    "        )\n",
    "        \n",
    "        # Use the last step scores if available, otherwise use the only available score\n",
    "        idx = -1 if len(mean_score) > 1 else 0\n",
    "        \n",
    "        results[env] = {\n",
    "            'with_prior_mean': mean_score[idx] if idx < len(mean_score) and not np.isnan(mean_score[idx]) else \"N/A\",\n",
    "            'with_prior_ci': ci_95[idx] if idx < len(ci_95) and not np.isnan(ci_95[idx]) else \"N/A\",\n",
    "            'no_prior_mean': mean_score_no_prior[idx] if idx < len(mean_score_no_prior) and not np.isnan(mean_score_no_prior[idx]) else \"N/A\",\n",
    "            'no_prior_ci': ci_95_no_prior[idx] if idx < len(ci_95_no_prior) and not np.isnan(ci_95_no_prior[idx]) else \"N/A\",\n",
    "            'norm_mu': norm_mu,\n",
    "            'norm_sigma': norm_sigma\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {env}: {e}\")\n",
    "        results[env] = {\n",
    "            'with_prior_mean': \"Error\",\n",
    "            'with_prior_ci': \"Error\",\n",
    "            'no_prior_mean': \"Error\",\n",
    "            'no_prior_ci': \"Error\",\n",
    "            'norm_mu': norm_mu,\n",
    "            'norm_sigma': norm_sigma\n",
    "        }\n",
    "\n",
    "# Create a DataFrame for the results\n",
    "df = pd.DataFrame(columns=[\n",
    "    'Environment', \n",
    "    'Norm μ',\n",
    "    'Norm σ',\n",
    "    'With Prior (Mean)', \n",
    "    'With Prior (95% CI)', \n",
    "    'No Prior (Mean)', \n",
    "    'No Prior (95% CI)'\n",
    "])\n",
    "\n",
    "for env, values in results.items():\n",
    "    new_row = pd.DataFrame({\n",
    "        'Environment': [env],\n",
    "        'Norm μ': [f\"{values['norm_mu']:.4f}\" if isinstance(values['norm_mu'], (int, float)) else values['norm_mu']],\n",
    "        'Norm σ': [f\"{values['norm_sigma']:.4f}\" if isinstance(values['norm_sigma'], (int, float)) else values['norm_sigma']],\n",
    "        'With Prior (Mean)': [f\"{values['with_prior_mean']:.4f}\" if isinstance(values['with_prior_mean'], (int, float)) else values['with_prior_mean']],\n",
    "        'With Prior (95% CI)': [f\"±{values['with_prior_ci']:.4f}\" if isinstance(values['with_prior_ci'], (int, float)) else values['with_prior_ci']],\n",
    "        'No Prior (Mean)': [f\"{values['no_prior_mean']:.4f}\" if isinstance(values['no_prior_mean'], (int, float)) else values['no_prior_mean']],\n",
    "        'No Prior (95% CI)': [f\"±{values['no_prior_ci']:.4f}\" if isinstance(values['no_prior_ci'], (int, float)) else values['no_prior_ci']]\n",
    "    })\n",
    "    df = pd.concat([df, new_row], ignore_index=True)\n",
    "\n",
    "# Display the results table\n",
    "try:\n",
    "    print(tabulate(df, headers='keys', tablefmt='pretty', showindex=False))\n",
    "except NameError:\n",
    "    print(df.to_string(index=False))\n",
    "\n",
    "# Save results to a CSV file\n",
    "output_path = os.path.join(results_dir, f\"{model}_{exp}_{goal}_all_environments.csv\")\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"Results saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (boxing-gym-env)",
   "language": "python",
   "name": "boxing-gym-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
